{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling"
      ],
      "metadata": {
        "id": "93GkqZARHZf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r app"
      ],
      "metadata": {
        "id": "pZf_3zCqRTgZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import f1_score, precision_recall_curve, auc, balanced_accuracy_score, accuracy_score\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('data/bank.csv')\n",
        "\n",
        "# Define feature groups\n",
        "numerical_features = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "binary_features = ['deposit', 'housing', 'default']\n",
        "categorical_features = ['job', 'marital', 'contact', 'poutcome']\n",
        "ordinal_features = ['education', 'month']\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numerical_transformer = StandardScaler()\n",
        "\n",
        "# Preprocessing for binary data (using OneHotEncoder with drop='if_binary')\n",
        "binary_transformer = OneHotEncoder(drop='if_binary', sparse=False)\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "\n",
        "# Preprocessing for Ordinal Features\n",
        "education_categories = ['unknown', 'primary', 'secondary', 'tertiary']\n",
        "month_categories = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
        "ordinal_transformer = OrdinalEncoder(categories=[education_categories, month_categories])\n",
        "\n",
        "# Combine all transformers\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('bin', binary_transformer, binary_features),\n",
        "        ('cat', categorical_transformer, categorical_features),\n",
        "        ('ord', ordinal_transformer, ordinal_features)\n",
        "    ])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = data.drop(columns=['loan'])\n",
        "y = data['loan'].apply(lambda x: 1 if x == 'yes' else 0)\n",
        "\n",
        "# First split: 90% for training and test, 10% for holdout (to be evaluated at the end)\n",
        "X_train_full, X_holdout, y_train_full, y_holdout = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
        "\n",
        "# Preprocess the 90% training set before applying SMOTE\n",
        "X_train_full_preprocessed = preprocessor.fit_transform(X_train_full)\n",
        "\n",
        "# Handle class imbalance using SMOTE on the training set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_full_preprocessed, y_train_full)\n",
        "\n",
        "# Split the resampled data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled)\n",
        "\n",
        "# Preprocess the holdout set\n",
        "X_holdout_preprocessed = preprocessor.transform(X_holdout)\n",
        "\n",
        "# Define pipelines for each model\n",
        "pipelines = {\n",
        "    'Logistic Regression': Pipeline(steps=[\n",
        "        ('classifier', LogisticRegression(solver='liblinear', class_weight='balanced'))\n",
        "    ]),\n",
        "    'Decision Tree': Pipeline(steps=[\n",
        "        ('classifier', DecisionTreeClassifier(random_state=42, max_depth=5, class_weight='balanced'))\n",
        "    ]),\n",
        "    'Random Forest': Pipeline(steps=[\n",
        "        ('classifier', RandomForestClassifier(random_state=42, n_estimators=100, max_depth=5, class_weight='balanced'))\n",
        "    ]),\n",
        "    'XGBoost': Pipeline(steps=[\n",
        "        ('classifier', xgb.XGBClassifier(random_state=42, eval_metric='logloss',\n",
        "                                         scale_pos_weight=(len(y_train) - sum(y_train)) / sum(y_train)))\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Model Ensembling using Voting Classifier (soft voting)\n",
        "voting_pipeline = VotingClassifier(estimators=[\n",
        "    ('lr', pipelines['Logistic Regression']),\n",
        "    ('dt', pipelines['Decision Tree']),\n",
        "    ('rf', pipelines['Random Forest']),\n",
        "    ('xgb', pipelines['XGBoost'])\n",
        "], voting='soft')\n",
        "\n",
        "# Train Voting Classifier\n",
        "voting_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Store model results for F1-Score, PR AUC, Accuracy, and Balanced Accuracy\n",
        "model_reports = {}\n",
        "pr_auc_scores = {}\n",
        "accuracies = {}\n",
        "balanced_accuracies = {}\n",
        "pr_curves = {}\n",
        "\n",
        "for model_name, model_pipeline in pipelines.items():\n",
        "    model_pipeline.fit(X_train, y_train)\n",
        "    y_pred = model_pipeline.predict(X_test)\n",
        "    y_pred_proba = model_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate F1-Score\n",
        "    model_reports[model_name] = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Precision-Recall Curve and AUC\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "    pr_auc = auc(recall, precision)\n",
        "    pr_auc_scores[model_name] = pr_auc\n",
        "    pr_curves[model_name] = (precision, recall)\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracies[model_name] = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Calculate Balanced Accuracy\n",
        "    balanced_accuracies[model_name] = balanced_accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Perform cross-validation for Balanced Accuracy\n",
        "    cv_scores = cross_val_score(model_pipeline, X_train, y_train, cv=5, scoring='balanced_accuracy')\n",
        "    print(f\"{model_name} - Cross-validation Balanced Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "# Add Voting Classifier Results\n",
        "y_pred_voting = voting_pipeline.predict(X_test)\n",
        "y_pred_proba_voting = voting_pipeline.predict_proba(X_test)[:, 1]\n",
        "model_reports['Voting Classifier'] = f1_score(y_test, y_pred_voting)\n",
        "\n",
        "# Precision-Recall for Voting Classifier\n",
        "precision_voting, recall_voting, _ = precision_recall_curve(y_test, y_pred_proba_voting)\n",
        "pr_auc_voting = auc(recall_voting, precision_voting)\n",
        "pr_auc_scores['Voting Classifier'] = pr_auc_voting\n",
        "\n",
        "# Accuracy for Voting Classifier\n",
        "accuracies['Voting Classifier'] = accuracy_score(y_test, y_pred_voting)\n",
        "\n",
        "# Balanced Accuracy for Voting Classifier\n",
        "balanced_accuracies['Voting Classifier'] = balanced_accuracy_score(y_test, y_pred_voting)\n",
        "\n",
        "# Create a DataFrame for the results\n",
        "df_results = pd.DataFrame({\n",
        "    'Model': list(model_reports.keys()),\n",
        "    'F1-Score': list(model_reports.values()),\n",
        "    'PR AUC': list(pr_auc_scores.values()),\n",
        "    'Accuracy': list(accuracies.values()),\n",
        "    'Balanced Accuracy': list(balanced_accuracies.values())\n",
        "})\n",
        "\n",
        "# Display the DataFrame for test set\n",
        "print(\"Test Set Results:\")\n",
        "print(df_results)\n",
        "\n",
        "# Evaluate on holdout set\n",
        "holdout_results = {}\n",
        "holdout_pr_auc_scores = {}\n",
        "holdout_accuracies = {}\n",
        "holdout_balanced_accuracies = {}\n",
        "\n",
        "for model_name, model_pipeline in pipelines.items():\n",
        "    y_pred_holdout = model_pipeline.predict(X_holdout_preprocessed)\n",
        "    y_pred_proba_holdout = model_pipeline.predict_proba(X_holdout_preprocessed)[:, 1]\n",
        "\n",
        "    # F1-Score on holdout\n",
        "    holdout_results[model_name] = f1_score(y_holdout, y_pred_holdout)\n",
        "\n",
        "    # Precision-Recall AUC on holdout\n",
        "    precision, recall, _ = precision_recall_curve(y_holdout, y_pred_proba_holdout)\n",
        "    holdout_pr_auc_scores[model_name] = auc(recall, precision)\n",
        "\n",
        "    # Accuracy on holdout\n",
        "    holdout_accuracies[model_name] = accuracy_score(y_holdout, y_pred_holdout)\n",
        "\n",
        "    # Balanced Accuracy on holdout\n",
        "    holdout_balanced_accuracies[model_name] = balanced_accuracy_score(y_holdout, y_pred_holdout)\n",
        "\n",
        "# Add Voting Classifier Results on holdout\n",
        "y_pred_voting_holdout = voting_pipeline.predict(X_holdout_preprocessed)\n",
        "y_pred_proba_voting_holdout = voting_pipeline.predict_proba(X_holdout_preprocessed)[:, 1]\n",
        "\n",
        "holdout_results['Voting Classifier'] = f1_score(y_holdout, y_pred_voting_holdout)\n",
        "\n",
        "# Precision-Recall for Voting Classifier on holdout\n",
        "precision_voting, recall_voting, _ = precision_recall_curve(y_holdout, y_pred_proba_voting_holdout)\n",
        "holdout_pr_auc_scores['Voting Classifier'] = auc(recall_voting, precision_voting)\n",
        "\n",
        "# Accuracy for Voting Classifier on holdout\n",
        "holdout_accuracies['Voting Classifier'] = accuracy_score(y_holdout, y_pred_voting_holdout)\n",
        "\n",
        "# Balanced Accuracy for Voting Classifier on holdout\n",
        "holdout_balanced_accuracies['Voting Classifier'] = balanced_accuracy_score(y_holdout, y_pred_voting_holdout)\n",
        "\n",
        "# Create a DataFrame for the holdout set results\n",
        "df_holdout_results = pd.DataFrame({\n",
        "    'Model': list(holdout_results.keys()),\n",
        "    'F1-Score': list(holdout_results.values()),\n",
        "    'PR AUC': list(holdout_pr_auc_scores.values()),\n",
        "    'Accuracy': list(holdout_accuracies.values()),\n",
        "    'Balanced Accuracy': list(holdout_balanced_accuracies.values())\n",
        "})\n",
        "\n",
        "# Display the DataFrame for holdout set\n",
        "print(\"\\nHoldout Set Results:\")\n",
        "print(df_holdout_results)\n",
        "\n",
        "# Select the best model based on Balanced Accuracy\n",
        "best_model_name = df_holdout_results.loc[df_holdout_results['Balanced Accuracy'].idxmax(), 'Model']\n",
        "best_model = pipelines[best_model_name] if best_model_name != 'Voting Classifier' else voting_pipeline\n",
        "\n",
        "print(f\"\\nBest model based on Balanced Accuracy: {best_model_name}\")\n",
        "\n",
        "# Feature Importance Analysis (for interpretable models)\n",
        "if best_model_name in ['Logistic Regression', 'Decision Tree', 'Random Forest']:\n",
        "    feature_names = (\n",
        "        numerical_features +\n",
        "        [f\"{feat}_1\" for feat in binary_features] +\n",
        "        list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)) +\n",
        "        ordinal_features\n",
        "    )\n",
        "\n",
        "    if best_model_name == 'Logistic Regression':\n",
        "        importances = best_model.named_steps['classifier'].coef_[0]\n",
        "    elif best_model_name in ['Decision Tree', 'Random Forest']:\n",
        "        importances = best_model.named_steps['classifier'].feature_importances_\n",
        "\n",
        "    feature_importance = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
        "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
        "\n",
        "    print(\"\\nTop 10 Most Important Features:\")\n",
        "    print(feature_importance.head(10))\n",
        "\n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x='importance', y='feature', data=feature_importance.head(20))\n",
        "    plt.title(f'Top 20 Feature Importances - {best_model_name}')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('feature_importance.png')\n",
        "    plt.close()\n",
        "\n",
        "# Plot model performance\n",
        "plt.figure(figsize=(12, 8))\n",
        "x = range(len(df_results['Model']))\n",
        "width = 0.2\n",
        "\n",
        "plt.bar(x, df_results['F1-Score'], width, label='F1-Score', align='center')\n",
        "plt.bar([i + width for i in x], df_results['PR AUC'], width, label='PR AUC', align='center')\n",
        "plt.bar([i + 2 * width for i in x], df_results['Accuracy'], width, label='Accuracy', align='center')\n",
        "plt.bar([i + 3 * width for i in x], df_results['Balanced Accuracy'], width, label='Balanced Accuracy', align='center')\n",
        "\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('Model Performance on Test Set')\n",
        "plt.xticks([i + 1.5 * width for i in x], df_results['Model'], rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_performance_test.png')\n",
        "plt.close()\n",
        "\n",
        "# Plot model performance on holdout set\n",
        "plt.figure(figsize=(12, 8))\n",
        "x = range(len(df_holdout_results['Model']))\n",
        "width = 0.2\n",
        "\n",
        "plt.bar(x, df_holdout_results['F1-Score'], width, label='F1-Score', align='center')\n",
        "plt.bar([i + width for i in x], df_holdout_results['PR AUC'], width, label='PR AUC', align='center')\n",
        "plt.bar([i + 2 * width for i in x], df_holdout_results['Accuracy'], width, label='Accuracy', align='center')\n",
        "plt.bar([i + 3 * width for i in x], df_holdout_results['Balanced Accuracy'], width, label='Balanced Accuracy', align='center')\n",
        "\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('Model Performance on Holdout Set')\n",
        "plt.xticks([i + 1.5 * width for i in x], df_holdout_results['Model'], rotation=45, ha='right')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_performance_holdout.png')\n",
        "plt.close()\n",
        "\n",
        "# Prepare the holdout set for JSON export\n",
        "holdout_data = X_holdout.copy()\n",
        "holdout_data['loan'] = y_holdout\n",
        "\n",
        "# Convert the holdout set to a list of dictionaries\n",
        "holdout_list = holdout_data.to_dict('records')\n",
        "\n",
        "# Export the holdout set as JSON\n",
        "os.makedirs('app/models/artifacts', exist_ok=True)\n",
        "with open('app/models/artifacts/validation_set.json', 'w') as f:\n",
        "    json.dump(holdout_list, f)\n",
        "\n",
        "print(\"Validation set exported as JSON successfully!\")\n",
        "\n",
        "# Test The Model\n",
        "# Create a sample input (make sure the order matches your feature list)\n",
        "sample_input = pd.DataFrame({\n",
        "    'age': [40],\n",
        "    'balance': [1500],\n",
        "    'day': [15],\n",
        "    'duration': [300],\n",
        "    'campaign': [2],\n",
        "    'pdays': [999],\n",
        "    'previous': [0],\n",
        "    'deposit': ['no'],\n",
        "    'housing': ['yes'],\n",
        "    'job': ['technician'],\n",
        "    'marital': ['married'],\n",
        "    'default': ['no'],\n",
        "    'contact': ['cellular'],\n",
        "    'poutcome': ['unknown'],\n",
        "    'education': ['secondary'],\n",
        "    'month': ['may']\n",
        "})\n",
        "\n",
        "print(\"\\nSample input:\")\n",
        "print(sample_input)\n",
        "\n",
        "# Preprocess the sample input\n",
        "sample_preprocessed = preprocessor.transform(sample_input)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = best_model.predict(sample_preprocessed)\n",
        "prediction_proba = best_model.predict_proba(sample_preprocessed)\n",
        "\n",
        "print(f\"\\nPrediction: {'Yes' if prediction[0] == 1 else 'No'}\")\n",
        "print(f\"Probability of Yes: {prediction_proba[0][1]:.2f}\")\n",
        "\n",
        "# Deploy Model\n",
        "# Create the artifacts directory if it doesn't exist\n",
        "os.makedirs('app/models/artifacts', exist_ok=True)\n",
        "\n",
        "# Export the best model\n",
        "with open('app/models/artifacts/best_model.pkl', 'wb') as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "with open('app/models/artifacts/preprocessor.pkl', 'wb') as f:\n",
        "    pickle.dump(preprocessor, f)\n",
        "\n",
        "print(\"Model and preprocessor saved successfully!\")\n",
        "\n",
        "# Print feature order for API input\n",
        "feature_names = (\n",
        "    numerical_features +\n",
        "    binary_features +\n",
        "    categorical_features +\n",
        "    ordinal_features\n",
        ")\n",
        "\n",
        "print(\"\\nFeature order for API input:\")\n",
        "for i, feature in enumerate(feature_names):\n",
        "    print(f\"{i+1}. {feature}\")\n",
        "\n",
        "# Print the shape of the preprocessed input\n",
        "print(f\"\\nShape of preprocessed input: {X_holdout_preprocessed.shape}\")\n",
        "\n",
        "print(\"\\nArtifacts generated:\")\n",
        "print(\"1. app/models/artifacts/best_model.pkl\")\n",
        "print(\"2. app/models/artifacts/preprocessor.pkl\")\n",
        "print(\"3. app/models/artifacts/validation_set.json\")\n",
        "print(\"4. feature_importance.png (if applicable)\")\n",
        "print(\"5. model_performance_test.png\")\n",
        "print(\"6. model_performance_holdout.png\")\n",
        "\n",
        "print(\"\\nExecution complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbBSa9CsLfhr",
        "outputId": "ec531ce4-7979-456e-c76f-aac41dd5d13e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Cross-validation Balanced Accuracy: 0.6482 (+/- 0.0089)\n",
            "Decision Tree - Cross-validation Balanced Accuracy: 0.7123 (+/- 0.0113)\n",
            "Random Forest - Cross-validation Balanced Accuracy: 0.7683 (+/- 0.0187)\n",
            "XGBoost - Cross-validation Balanced Accuracy: 0.9148 (+/- 0.0092)\n",
            "Test Set Results:\n",
            "                 Model  F1-Score    PR AUC  Accuracy  Balanced Accuracy\n",
            "0  Logistic Regression  0.675177  0.662233  0.650315           0.650330\n",
            "1        Decision Tree  0.720044  0.819830  0.709677           0.709685\n",
            "2        Random Forest  0.791074  0.884040  0.773048           0.773065\n",
            "3              XGBoost  0.919352  0.972312  0.923077           0.923068\n",
            "4    Voting Classifier  0.879017  0.957831  0.877839           0.877841\n",
            "\n",
            "Holdout Set Results:\n",
            "                 Model  F1-Score    PR AUC  Accuracy  Balanced Accuracy\n",
            "0  Logistic Regression  0.339036  0.242799  0.619517           0.673494\n",
            "1        Decision Tree  0.282098  0.138673  0.644584           0.597710\n",
            "2        Random Forest  0.330206  0.233815  0.680394           0.647405\n",
            "3              XGBoost  0.168317  0.238273  0.849597           0.538137\n",
            "4    Voting Classifier  0.297143  0.254574  0.779767           0.599812\n",
            "\n",
            "Best model based on Balanced Accuracy: Logistic Regression\n",
            "\n",
            "Top 10 Most Important Features:\n",
            "              feature  importance\n",
            "9           default_1    0.879851\n",
            "10         job_admin.    0.852774\n",
            "11    job_blue-collar    0.781526\n",
            "12   job_entrepreneur    0.642982\n",
            "17       job_services    0.580603\n",
            "19     job_technician    0.537145\n",
            "31   poutcome_unknown    0.370745\n",
            "16  job_self-employed    0.353086\n",
            "3            duration    0.162828\n",
            "14     job_management    0.120911\n",
            "Validation set exported as JSON successfully!\n",
            "\n",
            "Sample input:\n",
            "   age  balance  day  duration  campaign  pdays  previous deposit housing  \\\n",
            "0   40     1500   15       300         2    999         0      no     yes   \n",
            "\n",
            "          job  marital default   contact poutcome  education month  \n",
            "0  technician  married      no  cellular  unknown  secondary   may  \n",
            "\n",
            "Prediction: Yes\n",
            "Probability of Yes: 0.79\n",
            "Model and preprocessor saved successfully!\n",
            "\n",
            "Feature order for API input:\n",
            "1. age\n",
            "2. balance\n",
            "3. day\n",
            "4. duration\n",
            "5. campaign\n",
            "6. pdays\n",
            "7. previous\n",
            "8. deposit\n",
            "9. housing\n",
            "10. default\n",
            "11. job\n",
            "12. marital\n",
            "13. contact\n",
            "14. poutcome\n",
            "15. education\n",
            "16. month\n",
            "\n",
            "Shape of preprocessed input: (1117, 34)\n",
            "\n",
            "Artifacts generated:\n",
            "1. app/models/artifacts/best_model.pkl\n",
            "2. app/models/artifacts/preprocessor.pkl\n",
            "3. app/models/artifacts/validation_set.json\n",
            "4. feature_importance.png (if applicable)\n",
            "5. model_performance_test.png\n",
            "6. model_performance_holdout.png\n",
            "\n",
            "Execution complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MD-qiAkEPjWu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}